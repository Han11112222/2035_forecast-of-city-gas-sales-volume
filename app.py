import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import io
import requests
from pathlib import Path
from urllib.parse import quote
from sklearn.linear_model import LinearRegression

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŸ¢ 1. ê¸°ë³¸ ì„¤ì • & í°íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë„ì‹œê°€ìŠ¤ í†µí•© ë¶„ì„", layout="wide")

def set_korean_font():
    try:
        import matplotlib as mpl
        mpl.rcParams['axes.unicode_minus'] = False
        mpl.rc('font', family='Malgun Gothic') 
    except: pass

set_korean_font()

# ğŸŸ¢ ê¹ƒí—ˆë¸Œ ì„¤ì • (ë°±ì—…ìš©)
GITHUB_USER = "HanYeop"
REPO_NAME = "GasProject"
BRANCH = "main" 

# íŒŒì¼ëª… ìƒìˆ˜
FILE_SALES = "íŒë§¤ëŸ‰(ê³„íš_ì‹¤ì ).xlsx"       
FILE_SUPPLY_MJ = "ê³µê¸‰ëŸ‰ì‹¤ì _ê³„íš_ì‹¤ì _MJ.xlsx"
FILE_TEMP = "ê¸°ì˜¨.csv"

# ğŸŸ¢ [ë§¤í•‘] ì»¬ëŸ¼ëª… -> í‘œì¤€ ê·¸ë£¹ (ëª¨ë“  ì¼€ì´ìŠ¤ í¬í•¨)
USE_COL_TO_GROUP = {
    # ğŸ  ê°€ì •ìš©
    "ì·¨ì‚¬ìš©": "ê°€ì •ìš©", "ê°œë³„ë‚œë°©ìš©": "ê°€ì •ìš©", "ì¤‘ì•™ë‚œë°©ìš©": "ê°€ì •ìš©", "ìê°€ì—´ì „ìš©": "ê°€ì •ìš©",
    "ê°œë³„ë‚œë°©": "ê°€ì •ìš©", "ì¤‘ì•™ë‚œë°©": "ê°€ì •ìš©", "ê°€ì •ìš©ì†Œê³„": "ê°€ì •ìš©",
    
    # ğŸª ì˜ì—…ìš©
    "ì¼ë°˜ìš©": "ì˜ì—…ìš©", "ì¼ë°˜ìš©(1)": "ì˜ì—…ìš©", "ì¼ë°˜ìš©(2)": "ì˜ì—…ìš©", 
    "ì˜ì—…ìš©_ì¼ë°˜ìš©1": "ì˜ì—…ìš©", "ì˜ì—…ìš©_ì¼ë°˜ìš©2": "ì˜ì—…ìš©", 
    "ì¼ë°˜ìš©1(ì˜ì—…)": "ì˜ì—…ìš©", "ì¼ë°˜ìš©2(ì˜ì—…)": "ì˜ì—…ìš©", "ì¼ë°˜ìš©1": "ì˜ì—…ìš©",
    
    # ğŸ¢ ì—…ë¬´ìš©
    "ì—…ë¬´ë‚œë°©ìš©": "ì—…ë¬´ìš©", "ëƒ‰ë°©ìš©": "ì—…ë¬´ìš©", "ëƒ‰ë‚œë°©ìš©": "ì—…ë¬´ìš©", "ì£¼í•œë¯¸êµ°": "ì—…ë¬´ìš©",
    "ì—…ë¬´ìš©_ì¼ë°˜ìš©1": "ì—…ë¬´ìš©", "ì—…ë¬´ìš©_ì¼ë°˜ìš©2": "ì—…ë¬´ìš©", "ì—…ë¬´ìš©_ì—…ë¬´ë‚œë°©": "ì—…ë¬´ìš©", 
    "ì—…ë¬´ìš©_ëƒ‰ë‚œë°©": "ì—…ë¬´ìš©", "ì—…ë¬´ìš©_ì£¼í•œë¯¸êµ°": "ì—…ë¬´ìš©", 
    "ì¼ë°˜ìš©1(ì—…ë¬´)": "ì—…ë¬´ìš©", "ì¼ë°˜ìš©2(ì—…ë¬´)": "ì—…ë¬´ìš©",
    
    # ğŸ­ ì‚°ì—…ìš©
    "ì‚°ì—…ìš©": "ì‚°ì—…ìš©",
    
    # ğŸšŒ ìˆ˜ì†¡ìš©
    "ìˆ˜ì†¡ìš©(CNG)": "ìˆ˜ì†¡ìš©", "ìˆ˜ì†¡ìš©(BIO)": "ìˆ˜ì†¡ìš©", "CNG": "ìˆ˜ì†¡ìš©", "BIO": "ìˆ˜ì†¡ìš©",
    
    # âš¡ ë°œì „/ê¸°íƒ€
    "ì—´ë³‘í•©ìš©": "ì—´ë³‘í•©", "ì—´ë³‘í•©ìš©1": "ì—´ë³‘í•©", "ì—´ë³‘í•©ìš©2": "ì—´ë³‘í•©",
    "ì—°ë£Œì „ì§€ìš©": "ì—°ë£Œì „ì§€", "ì—°ë£Œì „ì§€": "ì—°ë£Œì „ì§€",
    "ì—´ì „ìš©ì„¤ë¹„ìš©": "ì—´ì „ìš©ì„¤ë¹„ìš©", "ì—´ì „ìš©ì„¤ë¹„ìš©(ì£¼íƒì™¸)": "ì—´ì „ìš©ì„¤ë¹„ìš©"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŸ¢ 2. í•µì‹¬: íŒŒì¼ ë¡œë” (ì‹œíŠ¸ ìë™ ì°¾ê¸° ê¸°ëŠ¥ íƒ‘ì¬)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=600)
def load_file_smart(file_obj, is_excel=True):
    """
    íŒŒì¼ ê°ì²´ë¥¼ ë°›ì•„ì„œ:
    1. ì—‘ì…€ì´ë©´ -> ì‹œíŠ¸ë³„ë¡œ ìª¼ê°œì„œ ë”•ì…”ë„ˆë¦¬ {'ì‹œíŠ¸ëª…': df} ë°˜í™˜
    2. CSVë©´ -> {'default': df} ë°˜í™˜
    """
    if file_obj is None: return None
    
    # 1. Excelë¡œ ì‹œë„
    try:
        excel = pd.ExcelFile(file_obj, engine='openpyxl')
        result = {}
        for sheet in excel.sheet_names:
            result[sheet] = excel.parse(sheet)
        return result
    except:
        # ì‹¤íŒ¨í•˜ë©´ í¬ì¸í„° ì´ˆê¸°í™” í›„ CSVë¡œ ì‹œë„
        if hasattr(file_obj, 'seek'): file_obj.seek(0)
        
    # 2. CSV (utf-8)
    try:
        df = pd.read_csv(file_obj, encoding='utf-8-sig')
        return {"default": df}
    except:
        if hasattr(file_obj, 'seek'): file_obj.seek(0)
        
    # 3. CSV (cp949)
    try:
        df = pd.read_csv(file_obj, encoding='cp949')
        return {"default": df}
    except:
        return None

def find_sheet_by_keyword(data_dict, keyword):
    """
    ë”•ì…”ë„ˆë¦¬ í‚¤(ì‹œíŠ¸ëª…) ì¤‘ì—ì„œ keywordê°€ í¬í•¨ëœ ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ ì°¾ìŒ
    ì˜ˆ: 'ê³µê¸‰ëŸ‰_ì‹¤ì 'ì„ ì°¾ìœ¼ë©´ ' ê³µê¸‰ëŸ‰_ì‹¤ì  (ìˆ˜ì •)' ê°™ì€ ì‹œíŠ¸ë„ ì°¾ì•„ëƒ„
    """
    if data_dict is None: return None
    
    # 1. ì •í™•í•œ ë§¤ì¹­
    if keyword in data_dict:
        return data_dict[keyword]
        
    # 2. ë¶€ë¶„ ë§¤ì¹­ (ê³µë°± ì œê±° í›„ ë¹„êµ)
    for sheet_name, df in data_dict.items():
        if keyword in sheet_name.replace(" ", ""):
            return df
            
    # 3. ëª» ì°¾ì•˜ìœ¼ë©´ None
    return None

def clean_dataframe(df):
    """ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ (ê³µí†µ)"""
    if df is None: return pd.DataFrame()
    
    df = df.copy()
    
    # ì»¬ëŸ¼ëª… ê³µë°± ì œê±°
    df.columns = df.columns.astype(str).str.strip()
    # Unnamed ì œê±°
    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
    
    # ë‚ ì§œ ì²˜ë¦¬ (MJ íŒŒì¼ ë“±)
    if 'ë‚ ì§œ' in df.columns:
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
        if 'ì—°' not in df.columns: df['ì—°'] = df['ë‚ ì§œ'].dt.year
        if 'ì›”' not in df.columns: df['ì›”'] = df['ë‚ ì§œ'].dt.month
        
    return df

def convert_to_long(df, label, mapping):
    """ë¶„ì„ ê°€ëŠ¥í•œ í˜•íƒœ(Long Format)ë¡œ ë³€í™˜"""
    df = clean_dataframe(df)
    if df.empty or 'ì—°' not in df.columns or 'ì›”' not in df.columns:
        return pd.DataFrame()
        
    records = []
    # ìˆ«ìí˜• ë³€í™˜
    df['ì—°'] = pd.to_numeric(df['ì—°'], errors='coerce')
    df['ì›”'] = pd.to_numeric(df['ì›”'], errors='coerce')
    df = df.dropna(subset=['ì—°', 'ì›”'])
    
    for col in df.columns:
        group = mapping.get(col)
        if not group: continue
        
        sub = df[['ì—°', 'ì›”']].copy()
        sub['ê·¸ë£¹'] = group
        sub['ìš©ë„'] = col
        sub['êµ¬ë¶„'] = label
        sub['ê°’'] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        records.append(sub)
        
    if not records: return pd.DataFrame()
    return pd.concat(records, ignore_index=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŸ¢ 3. ê¹ƒí—ˆë¸Œ íŒŒì¼ ê°€ì ¸ì˜¤ê¸° (ë°±ì—…)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=600)
def get_github_file(filename):
    url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/{BRANCH}/{quote(filename)}"
    try:
        r = requests.get(url)
        if r.status_code == 200: return io.BytesIO(r.content)
    except: pass
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŸ¢ 4. ë¶„ì„ & ì‹œê°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_dashboard(df, unit, mode_type):
    # ëª¨ë“œì— ë”°ë¼ ì˜ˆì¸¡ ì‹œì‘ ì—°ë„ ì„¤ì •
    start_pred_year = 2029 if mode_type == "supply" else 2026
    
    st.markdown("---")
    
    # 1. í•™ìŠµ ê¸°ê°„(ê³¼ê±°) ì„¤ì •
    all_years = sorted(df['ì—°'].unique())
    # ê¸°ë³¸ê°’: 2025ë…„ ì´í•˜
    default_yrs = [y for y in all_years if y <= 2025]
    if not default_yrs: default_yrs = all_years
    
    st.subheader("1ï¸âƒ£ ë¶„ì„ êµ¬ê°„ ì„¤ì •")
    train_years = st.multiselect("í•™ìŠµ(ê³¼ê±°) ì—°ë„ ì„ íƒ", all_years, default=default_yrs)
    
    # í•„í„°ë§: ì„ íƒëœ ì—°ë„ + í™•ì •ê³„íš(ë¯¸ë˜)
    df_filtered = df[df['ì—°'].isin(train_years) | (df['êµ¬ë¶„'].str.contains('ê³„íš'))]
    
    if df_filtered.empty:
        st.warning("ì„ íƒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ“Š ì‹¤ì /ê³„íš ë¶„ì„", "ğŸ”® 2035ë…„ ì˜ˆì¸¡"])
    
    with tab1:
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### ğŸ“ˆ ì›”ë³„ ì¶”ì´")
            mon_grp = df_filtered.groupby(['ì—°', 'ì›”'])['ê°’'].sum().reset_index()
            fig = px.line(mon_grp, x='ì›”', y='ê°’', color='ì—°', markers=True)
            st.plotly_chart(fig, use_container_width=True)
        with col2:
            st.markdown("##### ğŸ§± ìš©ë„ë³„ êµ¬ì„±")
            yr_grp = df_filtered.groupby(['ì—°', 'ê·¸ë£¹'])['ê°’'].sum().reset_index()
            fig2 = px.bar(yr_grp, x='ì—°', y='ê°’', color='ê·¸ë£¹')
            st.plotly_chart(fig2, use_container_width=True)
            
        st.dataframe(df_filtered.pivot_table(index='ì—°', columns='ê·¸ë£¹', values='ê°’', aggfunc='sum').style.format("{:,.0f}"), use_container_width=True)

    with tab2:
        st.info(f"ğŸ’¡ ì„ íƒí•œ ê³¼ê±° ë°ì´í„°ì™€ í™•ì • ê³„íš(2026~2028)ì„ ë°”íƒ•ìœ¼ë¡œ **{start_pred_year}ë…„ë¶€í„° 2035ë…„ê¹Œì§€** ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
        
        # ì˜ˆì¸¡ ë¡œì§
        train_grp = df_filtered.groupby(['ì—°', 'ê·¸ë£¹'])['ê°’'].sum().reset_index()
        groups = train_grp['ê·¸ë£¹'].unique()
        future_years = np.arange(start_pred_year, 2036).reshape(-1, 1)
        results = []
        
        method = st.radio("ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜", ["ì„ í˜• íšŒê·€", "2ì°¨ ê³¡ì„ ", "CAGR"], horizontal=True)
        
        for grp in groups:
            sub = train_grp[train_grp['ê·¸ë£¹'] == grp]
            if len(sub) < 2: continue
            
            X = sub['ì—°'].values
            y = sub['ê°’'].values
            pred = []
            
            if method == "ì„ í˜• íšŒê·€":
                model = LinearRegression(); model.fit(X.reshape(-1,1), y)
                pred = model.predict(future_years)
            elif method == "2ì°¨ ê³¡ì„ ":
                try: z = np.polyfit(X, y, 2); p = np.poly1d(z); pred = p(future_years.flatten())
                except: model = LinearRegression(); model.fit(X.reshape(-1,1), y); pred = model.predict(future_years)
            else: # CAGR
                try: cagr = (y[-1]/y[0])**(1/len(y)) - 1
                except: cagr = 0
                pred = [y[-1] * ((1+cagr)**(i+1)) for i in range(len(future_years))]
                
            pred = [max(0, p) for p in pred]
            
            # ê³¼ê±° ë°ì´í„°
            for yr, val in zip(sub['ì—°'], sub['ê°’']): 
                results.append({'ì—°': yr, 'ê·¸ë£¹': grp, 'ê°’': val, 'êµ¬ë¶„': 'ì‹¤ì /ê³„íš'})
            # ë¯¸ë˜ ì˜ˆì¸¡
            for yr, val in zip(future_years.flatten(), pred):
                results.append({'ì—°': yr, 'ê·¸ë£¹': grp, 'ê°’': val, 'êµ¬ë¶„': 'ì˜ˆì¸¡(AI)'})
                
        res_df = pd.DataFrame(results)
        
        fig_pred = px.line(res_df, x='ì—°', y='ê°’', color='ê·¸ë£¹', line_dash='êµ¬ë¶„', markers=True)
        fig_pred.add_vline(x=start_pred_year-0.5, line_dash="dash", line_color="green", annotation_text="ì˜ˆì¸¡ ì‹œì‘")
        st.plotly_chart(fig_pred, use_container_width=True)
        
        st.markdown("##### ğŸ“‹ ì—°ë„ë³„ ìƒì„¸ ì˜ˆì¸¡ê°’")
        pred_data = res_df[res_df['êµ¬ë¶„'] == 'ì˜ˆì¸¡(AI)']
        st.dataframe(pred_data.pivot_table(index='ì—°', columns='ê·¸ë£¹', values='ê°’').style.format("{:,.0f}"), use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŸ¢ 5. ë©”ì¸ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.title("ğŸ”¥ ë„ì‹œê°€ìŠ¤ íŒë§¤/ê³µê¸‰ í†µí•© ë¶„ì„")
    
    with st.sidebar:
        st.header("ì„¤ì •")
        mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["1. íŒë§¤ëŸ‰ ì˜ˆì¸¡", "2. ê³µê¸‰ëŸ‰ ì˜ˆì¸¡"])
        unit = st.radio("ë‹¨ìœ„", ["ë¶€í”¼(ì²œmÂ³)", "ì—´ëŸ‰(GJ)"])
        st.markdown("---")
        
    df_final = pd.DataFrame()
    
    # ğŸŸ¢ 1. íŒë§¤ëŸ‰ ëª¨ë“œ
    if mode.startswith("1"):
        with st.sidebar:
            st.warning("ğŸ“‚ **íŒë§¤ëŸ‰(ê³„íš_ì‹¤ì ).xlsx** ì—…ë¡œë“œ")
            up = st.file_uploader("íŒë§¤ëŸ‰ íŒŒì¼", type=["xlsx", "csv"], key="sales")
        
        # íŒŒì¼ í™•ë³´
        file_obj = up if up else get_github_file(FILE_SALES)
        
        if file_obj:
            # ë°ì´í„° ë¡œë“œ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
            data_dict = load_file_smart(file_obj)
            
            if data_dict:
                # ì‹œíŠ¸ ì°¾ê¸°
                df_p = find_sheet_by_keyword(data_dict, "ê³„íš")
                df_a = find_sheet_by_keyword(data_dict, "ì‹¤ì ")
                
                # CSVì¸ ê²½ìš° 'default' í‚¤ì— ìˆìŒ
                if df_p is None and df_a is None and "default" in data_dict:
                    df_a = data_dict["default"] # CSVëŠ” ë³´í†µ ì‹¤ì ìœ¼ë¡œ ê°„ì£¼
                
                long_p = convert_to_long(df_p, "ê³„íš", USE_COL_TO_GROUP)
                long_a = convert_to_long(df_a, "ì‹¤ì ", USE_COL_TO_GROUP)
                df_final = pd.concat([long_p, long_a], ignore_index=True)
            
            if df_final.empty:
                st.error("ğŸš¨ ë°ì´í„°ë¥¼ ì½ì—ˆìœ¼ë‚˜ ë¶„ì„í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. (ì»¬ëŸ¼ëª… í™•ì¸ í•„ìš”)")
        else:
            st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ íŒë§¤ëŸ‰ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            
    # ğŸŸ¢ 2. ê³µê¸‰ëŸ‰ ëª¨ë“œ (í˜•ë‹˜ ìš”ì²­ ë¡œì§)
    else:
        with st.sidebar:
            st.warning("ğŸ“‚ **ê³µê¸‰ëŸ‰ì‹¤ì _ê³„íš_ì‹¤ì _MJ.xlsx** ì—…ë¡œë“œ")
            st.caption("â€» ì‹œíŠ¸: 'ê³µê¸‰ëŸ‰_ì‹¤ì ', 'ê³µê¸‰ëŸ‰_ê³„íš' í¬í•¨ í•„ìˆ˜")
            up = st.file_uploader("ê³µê¸‰ëŸ‰ íŒŒì¼", type=["xlsx", "csv"], key="supply")
            
        file_obj = up if up else get_github_file(FILE_SUPPLY_MJ)
        
        if file_obj:
            data_dict = load_file_smart(file_obj)
            
            if data_dict:
                # 1) ê³µê¸‰ëŸ‰_ì‹¤ì  (ê³¼ê±°)
                df_hist = find_sheet_by_keyword(data_dict, "ê³µê¸‰ëŸ‰_ì‹¤ì ")
                # 2) ê³µê¸‰ëŸ‰_ê³„íš (2026~2028 í™•ì •)
                df_plan = find_sheet_by_keyword(data_dict, "ê³µê¸‰ëŸ‰_ê³„íš")
                
                # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
                if df_hist is None and df_plan is None:
                    if "default" in data_dict:
                        st.warning("âš ï¸ ì—‘ì…€ ì‹œíŠ¸ êµ¬ë¶„ì„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. CSV íŒŒì¼ë¡œ ì¸ì‹í•˜ì—¬ 'ì‹¤ì 'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                        df_hist = data_dict["default"]
                    else:
                        st.error(f"ğŸš¨ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°œê²¬ëœ ì‹œíŠ¸: {list(data_dict.keys())})")
                
                long_h = convert_to_long(df_hist, "ì‹¤ì ", USE_COL_TO_GROUP)
                long_p = convert_to_long(df_plan, "í™•ì •ê³„íš", USE_COL_TO_GROUP)
                
                df_final = pd.concat([long_h, long_p], ignore_index=True)
                
                if df_final.empty and (df_hist is not None or df_plan is not None):
                     st.error("ğŸš¨ ì‹œíŠ¸ëŠ” ì°¾ì•˜ìœ¼ë‚˜ ì»¬ëŸ¼ ë§¤í•‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì»¬ëŸ¼ëª…ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”)")
                     if df_hist is not None: st.write("ì‹¤ì  ë°ì´í„° ì»¬ëŸ¼:", df_hist.columns.tolist())
            else:
                st.error("ğŸš¨ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì•”í˜¸í™”ë˜ì—ˆê±°ë‚˜ ì†ìƒë¨)")
        else:
            st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ê³µê¸‰ëŸ‰ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    # ëŒ€ì‹œë³´ë“œ ë Œë”ë§
    if not df_final.empty:
        mode_key = "supply" if mode.startswith("2") else "sales"
        render_dashboard(df_final, unit, mode_key)

if __name__ == "__main__":
    main()
